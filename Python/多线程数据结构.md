#  Python 多线程数据结构

在 Python 中，concurrent 模块（主要是 concurrent.futures）本身不直接提供特定的数据结构，而是提供并发执行的工具（如线程池和进程池）。

不过，当讨论并发编程时，某些数据结构可以与并发机制结合使用，以确保线程安全或进程安全地处理共享数据。以下是 Python 中与并发相关的数据结构以及如何在并发场景中使用它们的概述。

1. **Python 中与并发相关的数据结构**

Python 标准库提供了一些线程安全或适合并发场景的数据结构，主要在 queue 模块和 collections 模块中：

(1) queue.Queue（线程安全队列）

- **用途**：用于线程间的任务分发和数据共享。

- **特点**：

  - 线程安全的 FIFO（先进先出）队列，适合多线程生产者-消费者模型。
  - 提供阻塞操作（如 put() 和 get()），自动处理锁。

- **示例**（使用 concurrent.futures.ThreadPoolExecutor）：

  python

  ```python
  import queue
  import concurrent.futures
  
  q = queue.Queue()
  
  def worker(item):
      print(f"Processing {item}")
      return item * 2
  
  # 生产者：向队列添加任务
  for i in range(5):
      q.put(i)
  
  # 消费者：使用线程池处理队列中的任务
  with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
      while not q.empty():
          item = q.get()
          executor.submit(worker, item)
  ```

- **注意**：queue.Queue 仅用于线程，不适用于多进程（进程间需要 multiprocessing.Queue）。

(2) queue.LifoQueue 和 queue.PriorityQueue

- **LifoQueue**：线程安全的 LIFO（后进先出）队列，类似栈。
- **PriorityQueue**：线程安全的优先级队列，元素按优先级排序。
- **用法**：与 queue.Queue 类似，适合需要特定顺序的并发任务。

(3) collections.deque（线程安全双端队列）

- **用途**：高效的双端队列，支持线程安全的 append 和 pop 操作。

- **特点**：

  - 内部实现为线程安全（GIL 保护），但需要显式加锁来保护复杂操作。
  - 适合快速追加和弹出元素。

- **示例**：

  python

  ```python
  from collections import deque
  import threading
  
  d = deque()
  lock = threading.Lock()
  
  def append_item(item):
      with lock:
          d.append(item)
          print(f"Appended {item}")
  
  threads = [threading.Thread(target=append_item, args=(i,)) for i in range(5)]
  for t in threads:
      t.start()
  for t in threads:
      t.join()
  print(d)
  ```

(4) multiprocessing.Queue（进程安全队列）

- **用途**：用于多进程间的任务分发和数据共享。

- **特点**：类似 queue.Queue，但为进程间通信设计，基于管道实现。

- **示例**：

  python

  ```python
  from multiprocessing import Process, Queue
  
  def worker(q):
      item = q.get()
      print(f"Processing {item}")
  
  q = Queue()
  for i in range(5):
      q.put(i)
  
  processes = [Process(target=worker, args=(q,)) for _ in range(2)]
  for p in processes:
      p.start()
  for p in processes:
      p.join()
  ```

(5) multiprocessing.Manager 的数据结构

- **用途**：提供进程间共享的线程安全数据结构，如 List、Dict、Namespace 等。

- **特点**：通过 Manager 创建的结构可以被多个进程安全访问。

- **示例**：

  python

  ```python
  from multiprocessing import Process, Manager
  
  def worker(shared_dict, key, value):
      shared_dict[key] = value
  
  with Manager() as manager:
      shared_dict = manager.dict()
      processes = [Process(target=worker, args=(shared_dict, i, i*2)) for i in range(5)]
      for p in processes:
          p.start()
      for p in processes:
          p.join()
      print(shared_dict)
  ```

- **并发场景中的其他数据结构**

虽然 Python 没有为并发专门设计的更多内置数据结构，但可以通过锁机制将标准数据结构（如 list、dict）改造成线程安全的版本：

(1) 使用 threading.Lock 或 threading.RLock

- **用途**：保护共享的 list、dict 等非线程安全数据结构。

- **示例**：

  python

  ```python
  import threading
  
  shared_list = []
  lock = threading.Lock()
  
  def append_item(item):
      with lock:
          shared_list.append(item)
          print(f"Appended {item}")
  
  threads = [threading.Thread(target=append_item, args=(i,)) for i in range(5)]
  for t in threads:
      t.start()
  for t in threads:
      t.join()
  print(shared_list)
  ```

(2) 使用 concurrent.futures 管理并发

- **ThreadPoolExecutor** 和 **ProcessPoolExecutor** 本身不提供数据结构，但可以与上述数据结构结合，管理并发任务。

- **示例**（结合 queue.Queue 和 ThreadPoolExecutor）：

  python

  ```python
  import concurrent.futures
  import queue
  
  q = queue.Queue()
  
  def process_item(item):
      return f"Processed {item}"
  
  # 添加任务
  for i in range(5):
      q.put(i)
  
  results = []
  with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
      futures = [executor.submit(process_item, q.get()) for _ in range(q.qsize())]
      for future in concurrent.futures.as_completed(futures):
          results.append(future.result())
  print(results)
  ```

- **注意事项**

- **线程安全 vs 进程安全**：
  - queue.Queue、collections.deque（加锁后）适用于线程。
  - multiprocessing.Queue、multiprocessing.Manager 适用于进程。
- **GIL 限制**：
  - Python 的 GIL（全局解释器锁）限制了多线程在 CPU 密集型任务中的性能，建议 CPU 密集型任务使用 ProcessPoolExecutor。
- **性能优化**：
  - 使用 queue.PriorityQueue 或 heapq（加锁）实现优先级调度。
  - 尽量减少锁的粒度，避免死锁。
- **数据结构选择**：
  - 任务分发：queue.Queue 或 multiprocessing.Queue。
  - 共享状态：multiprocessing.Manager 的 Dict 或 List。
  - 快速追加/弹出：collections.deque（加锁）。
- **扩展：第三方库**

如果需要更高级的并发数据结构，可以考虑第三方库：

- **redis**：使用 Redis 提供的线程/进程安全的列表、集合等数据结构，适合分布式并发。
- **blist** 或 **sortedcontainers**：提供高效的并发友好数据结构（需加锁）。
- **pyrsistent**：提供不可变数据结构，适合并发环境避免竞争。

总结

Python 中与并发直接相关的数据结构主要是 queue.Queue（线程安全）、multiprocessing.Queue（进程安全）和 multiprocessing.Manager 的共享结构。其他数据结构（如 list、dict、deque）可通过锁或并发工具（如 concurrent.futures）适配并发场景。推荐根据任务类型选择：

- 线程任务：queue.Queue + ThreadPoolExecutor。
- 进程任务：multiprocessing.Queue + ProcessPoolExecutor。
- 共享状态：multiprocessing.Manager 或锁保护的标准数据结构。

如果有具体的并发场景或数据结构需求（例如优先级队列、并发字典等），请提供更多细节，我可以进一步定制示例或方案！